{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-12T01:53:54.026333Z","iopub.execute_input":"2023-10-12T01:53:54.027085Z","iopub.status.idle":"2023-10-12T01:53:54.042956Z","shell.execute_reply.started":"2023-10-12T01:53:54.027048Z","shell.execute_reply":"2023-10-12T01:53:54.041858Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"![](https://d33wubrfki0l68.cloudfront.net/4abebe27614d96661267aa3d020abab97adf4a5e/4e221/images/multilingual-transformers-2.jpg)","metadata":{}},{"cell_type":"code","source":"import datasets \n\nted = datasets.load_dataset('ted_multi', split='train')\nted","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:53:54.045526Z","iopub.execute_input":"2023-10-12T01:53:54.046332Z","iopub.status.idle":"2023-10-12T01:55:13.083756Z","shell.execute_reply.started":"2023-10-12T01:53:54.046299Z","shell.execute_reply":"2023-10-12T01:55:13.082782Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed21fbc0906246c7b9d51e7b5ec66d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fda072d850a48298c4aaf5dd421d708"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset ted_multi_translate/plain_text (download: 335.91 MiB, generated: 754.37 MiB, post-processed: Unknown size, total: 1.06 GiB) to /root/.cache/huggingface/datasets/ted_multi_translate/plain_text/1.0.0/36fba834c6533853a24b6398207b3a1567455da505ceeed63bd94a5b7c6fd8b9...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/352M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dae886f31664411aa7c1b1ac3087c0a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/258098 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/6049 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7213 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset ted_multi_translate downloaded and prepared to /root/.cache/huggingface/datasets/ted_multi_translate/plain_text/1.0.0/36fba834c6533853a24b6398207b3a1567455da505ceeed63bd94a5b7c6fd8b9. Subsequent calls will reuse this data.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['translations', 'talk_name'],\n    num_rows: 258098\n})"},"metadata":{}}]},{"cell_type":"code","source":"ted[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:55:13.085033Z","iopub.execute_input":"2023-10-12T01:55:13.086286Z","iopub.status.idle":"2023-10-12T01:55:13.097663Z","shell.execute_reply.started":"2023-10-12T01:55:13.086227Z","shell.execute_reply":"2023-10-12T01:55:13.096451Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'translations': {'language': ['ar',\n   'bg',\n   'de',\n   'el',\n   'en',\n   'es',\n   'eu',\n   'fa',\n   'fr',\n   'fr-ca',\n   'he',\n   'hr',\n   'hu',\n   'it',\n   'ja',\n   'ko',\n   'nb',\n   'nl',\n   'pl',\n   'pt',\n   'pt-br',\n   'ro',\n   'ru',\n   'sq',\n   'tr',\n   'vi',\n   'zh-cn',\n   'zh-tw'],\n  'translation': ['من ضمن جميع المثبطات المقلقة التي نعاني منها اليوم نفكر في المقام الاول في الامور المالية والاقتصادية واكثر ما يهمني بشكل اكثر هو عجز الحوار السياسي — قدرتنا على فهم الصراعات الحديثة على ماهي عليه , بالذهاب الى اصلها الفعلي وعلى فهم اللاعبين الرئيسيين وعلى التعامل معهم',\n   'Наред с всички обезпокоителни дефицити , с които се сблъскваме днес - ние основно мислим за финансовите и икономическите - този , който ме безпокои най-вече е липсата на политически диалог - нашата способност да подходим към съвременните конфликти както те присъстват , да стигнем до източника на това , от което те произтичат и да разберем ключовите участници и да се разберем с тях .',\n   'Unter den schwierigen Problemen , mit denen wir heutzutage ringen – wir denken hier in erster Linie an finanzielle und ökonomische Probleme – dasjenige , das mich am meisten beunruhigt , ist der Mangel an politischem Dialog : Unsere Fähigkeit , mit modernen Konflikten umzugehen , zur ihrer eigentlichen Quelle zu gehen , die Hauptakteure zu verstehen , und mit ihnen umzugehen .',\n   'Ανάμεσα σε όλα τα ανησυχητικά ελλείμματα που αντιμετωπίζουμε σήμερα - σκεφτόμαστε το πολιτικό και οικονομικό έλλειμμα αρχικά - αυτό που με ανησυχεί περισσότερο είναι το έλλειμμα του πολιτικού διαλόγου , η ικανότητά μας να αντιμετωπίσουμε σύγχρονες συγκρούσεις όπως είναι , να πάμε στην πηγή της αιτίας τους και να καταλάβουμε τους παίκτες-κλειδιά και να τους αντιμετωπίσουμε .',\n   'Amongst all the troubling deficits we struggle with today — we think of financial and economic primarily — the ones that concern me most is the deficit of political dialogue — our ability to address modern conflicts as they are , to go to the source of what they &apos;re all about and to understand the key players and to deal with them .',\n   'De todos los déficits preocupantes a los que nos enfrentamos hoy , pensamos principalmente en el financiero y en el económico . Pero el que más me preocupa es el déficit del diálogo político , nuestra capacidad para tratar conflictos modernos tal y como son , ir a la raíz de por qué existen y entender a los actores principales y tratar con ellos .',\n   'Gaur egun aurrean ditugun gabezia kezkagarri guztietatik , nagusiki finantza eta ekonomian pentsatzen dugu , ni gehien kezkatzen nauena elkarrizketa politiko falta da ordea . Gatazka modernoak direna bezala jorratzeko gaitasuna , gatazkaren errora iristea eta aktore nagusiak ulertzea eta haiekin tratatzea .',\n   'از میان همه کاستی های نگران کننده ای که امروزه با آنها درگیریم — بیشتر اوقات ذهنمان معطوف جنبه های مالی و اقتصادی است — آنچه مرا بیش از همه نگران می کند کمبود گفتگوی سیاسی است — یعنی توانایی ما در پرداختن به درگیری های مدرن آنگونه که هستند ، در ریشه یابی آنها و شناخت و درک بازیگران کلیدی و پرداختن به آنها .',\n   'Parmi tous les déficits inquiétants contre lesquels nous luttons aujourd&apos; hui — surtout en matière économique et financière — celui qui me préoccupe le plus est le déficit du dialogue politique — notre capacité à résoudre les conflits modernes tels qu&apos; ils sont , d&apos; aller à la source de ce qu&apos; ils sont et d&apos; identifier les principaux acteurs et de traiter avec eux .',\n   'Parmi tous les déficits que nous accusons aujourd &apos; hui , et même si l &apos; on pense qu &apos; ils sont surtout d &apos; ordre financier et économique , celui qui me préoccupe le plus , c &apos; est le déficit du dialogue politique ; C &apos; est-à-dire notre capacité à gérer les conflits modernes tels qu &apos; ils sont , de pouvoir comprendre leur source même et les acteurs clés qui les composent , pour ensuite s &apos; en occuper .',\n   'מתוך מכלול הגרעונות המציקים שעמם אנחנו מתמודדים היום אנחנו חושבים בראש וראשונה על הגרעון הפיננסי והכלכלי — הגרעון שמדאיג אותי יותר מכל הוא המחסור או ההעדר בדיאלוג פוליטי — שמשפיע על היכולת שלנו להתמודד עם סכסוכים מודרניים כמו שהם , לרדת לשורש העניין , להבין מי הם השחקנים העיקריים ולהתמודד איתם .',\n   'Među svim zabrinjavajućim problemima s kojima se danas susrećemo , tu prvenstveno mislimo na ekonomske i financijske , ali oni koji me najviše zabrinjavaju nedostatci su političkog dijaloga , naše sposobnosti da se nosimo s modernim sukobima kao takvima , da doprijemo do njihove biti i da shvatimo ključne igrače te da se s njima obračunamo .',\n   'Az összes aggasztó hiány közül , amikkel ma küszködünk — — elsősorban pénzügyi és a gazdasági hiányra gondolunk — engem leginkább a politikai párbeszéd hiánya aggaszt — azé a képességünké , hogy a modern konfliktusokat , annak vegyük , amik , hogy visszamenjünk az eredetükig , amiről valójában szólnak , és hogy megértsük a kulcsszereplőket és kezeljük őket .',\n   'Tra tutti i problematici disavanzi contro i quali combattiamo oggi — principalmente pensiamo a quelli finanziari o economici — quello che mi preoccupa maggiormente è il deficit del dialogo politico — la nostra capacità di indirizzarci ai conflitti moderni nel modo in cui sono , per andare alla fonte di ciò che riguardano , per capire chi sono i giocatori chiave e per trattare con loro .',\n   '我々が今日直面している 様々な機能不全のなかで — 財政や経済が最初に思いつきますが — 私が一番 憂慮しているのは 政治的対話の欠乏です 我々が 近年の紛争において 状況を把握し その根本原因を探り 中心人物を理解し 彼らと交渉をする能力です',\n   '오늘날 우리가 겪고 있는 문제를 야기하는 모든 결핍들 중에서 우리는 주로 재정과 경제를 생각합니다만 , 제가 가장 우려하는 것들은 정치적 대화의 결핍입니다 . 우리가 현대의 갈등들을 그 자체로서 논하고 , 그 갈등들이 진정 무엇에 관한것이었는지 그 근원을 알아보고 , 그 핵심 인물들을 이해하고 , 그리고 그들을 상대하는 능력말입니다 .',\n   'Blant alle de urovekkende manglene vi strever med i dag — vi tenker primært på finansielle og økonomiske — de som bekymrer meg mest er mangelen på politisk dialog — vår evne til å adressere moderne konflikter slik de er , å finne kilden for det de egentlig handler om og å forstå nøkkelspillerne og å forholde seg til dem .',\n   'Van al onze verontrustende tekorten tegenwoordig — als eerste denk je aan financiële en economische — is het meest belangrijke voor mij het tekort aan politieke dialoog : ons onvermogen met moderne conflicten om te gaan , naar de kern te gaan en de sleutelfiguren te begrijpen , en ze aan te pakken .',\n   'Wśród problemów z jakimi zmagamy się dziś , mamy na myśli przede wszystkim te finansowe i ekonomiczne . Problemem , który mnie interesuje najbardziej jest deficyt politycznego dialogu , brak umiejętności odniesienia się do współczesnych konfliktów , dotarcia do ich źródła i zrozumienia kim są ich kluczowi gracze i jak z nimi postępować .',\n   'Entre todas as grandes privações com que nos debatemos hoje — pensamos em financeiras e económicas primeiro — aquela que mais me preocupa é a falta de diálogo político — a nossa capacidade de abordar conflitos modernos como eles são , de ir à raiz do que eles são e perceber os agentes-chave e lidar com eles .',\n   'Entre todos os déficits preocupantes com que lidamos hoje — nós pensamos principalmente nos financeiros ou econômicos — o que me preocupa mais é a falta de diálogo político — nossa habilidade de lidar com os conflitos modernos como eles são , ir à fonte do que eles tratam , entender os atores chave e lidar com eles',\n   'Printre toate deficitele îngrijorătoare cu care ne luptăm azi — ne gândim la cele financiare şi economice în primul rând — cel care mă preocupă cel mai mult este deficitul dialogului politic — abilitatea noastră de a aborda conflictele moderne aşa cum se prezintă , de a ajunge la sursa care le provoacă să înţelegem jucătorii cheie şi să le facem faţă .',\n   'Среди всех дефицитов , беспокоящих нас сегодня — прежде всего финансового и экономического — меня больше всего волнует дефицит политического диалога : нашей способности реагировать на современные конфликты в их настоящем виде , осознавать , что лежит в их основе , кто является ключевыми игроками , и как с ними работать .',\n   'Midis gjithe problemeve me deficite ne luftojme me te sotmen — ne kryesisht mendojme per financa dhe ekonomi — per te cilat shqetsohemi me shume eshte deficiti i dialogu politike — aftesia jone per te adresuar konflikte moderne ashtu sic ato jane , për të shkuar tek burimi dhe per te kuptuar lojtaret kyç dhe te merremi me ta .',\n   'Günümüzde mücadele ettiğimiz bütün eksiklikler arasında — öncelikle finansal ve ekonomik olanları düşünüyoruz — beni en çok ilgilendireni politik diyalog eksikliği — modern çatışmaları oldukları haliyle irdeleme becerimiz , varoluş nedeninin kaynağına gitmek ve kilit oyuncuları anlamak ve onlarla anlaşmak .',\n   'Trong số tất cả những thâm hụt phiền phức mà chúng ta đang phải vật lộn để vượt qua — thường thì chúng ta chủ yếu nghĩ về tài chính và kinh tế — điều khiến tôi quan tâm nhất là sự thâm hụt trong đối thoại chính trị — khả năng chúng ta giải quyết các cuộc xung đột hiện đại đúng với bản chất của chúng , để đi tới nguồn gốc của vấn đề và để hiểu những nhân vật chủ chốt trong cuộc xung đột để có cách giải quyết với họ .',\n   '当今我们与之斗争的所有不足中 大家认为经济和金融缺陷是最紧要的 但最使我担忧的 是政治对话的不足 - 包括我们处理实际上的 现代冲突的能力 ， 追溯到这些冲突问题本源的能力 ， 以及理解关键人物 ， 并与他们沟通的能力 。',\n   '在所有今日世人仍然必需去努力實現的種種令人憂心的缺點之中 — - 我們認為金融和經濟是最根本主要的 — 但是我最關心的是 是政治上對話的不足 — 我們有能力應付現今的衝突 實際上就是 ， 找到事情發生的原因 了解關鍵人物 再和他們打交道 。']},\n 'talk_name': 'jonas_gahr_store_in_defense_of_dialogue'}"},"metadata":{}}]},{"cell_type":"code","source":"idx = ted[0]['translations']['language'].index('en')\nidx ","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:55:13.098931Z","iopub.execute_input":"2023-10-12T01:55:13.099545Z","iopub.status.idle":"2023-10-12T01:55:13.107730Z","shell.execute_reply.started":"2023-10-12T01:55:13.099499Z","shell.execute_reply":"2023-10-12T01:55:13.106471Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"source = ted[0]['translations']['translation'][idx]\nsource","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:55:13.111656Z","iopub.execute_input":"2023-10-12T01:55:13.112580Z","iopub.status.idle":"2023-10-12T01:55:13.120253Z","shell.execute_reply.started":"2023-10-12T01:55:13.112546Z","shell.execute_reply":"2023-10-12T01:55:13.119180Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'Amongst all the troubling deficits we struggle with today — we think of financial and economic primarily — the ones that concern me most is the deficit of political dialogue — our ability to address modern conflicts as they are , to go to the source of what they &apos;re all about and to understand the key players and to deal with them .'"},"metadata":{}}]},{"cell_type":"code","source":"pairs = [] \n\nfor i, translation in enumerate(ted[0]['translations']['translation']):\n    if i != idx:\n        pairs.append((source, translation))\n        \npairs[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:55:13.125035Z","iopub.execute_input":"2023-10-12T01:55:13.125992Z","iopub.status.idle":"2023-10-12T01:55:13.135129Z","shell.execute_reply.started":"2023-10-12T01:55:13.125959Z","shell.execute_reply":"2023-10-12T01:55:13.134070Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Amongst all the troubling deficits we struggle with today — we think of financial and economic primarily — the ones that concern me most is the deficit of political dialogue — our ability to address modern conflicts as they are , to go to the source of what they &apos;re all about and to understand the key players and to deal with them .',\n 'من ضمن جميع المثبطات المقلقة التي نعاني منها اليوم نفكر في المقام الاول في الامور المالية والاقتصادية واكثر ما يهمني بشكل اكثر هو عجز الحوار السياسي — قدرتنا على فهم الصراعات الحديثة على ماهي عليه , بالذهاب الى اصلها الفعلي وعلى فهم اللاعبين الرئيسيين وعلى التعامل معهم')"},"metadata":{}}]},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:55:13.136548Z","iopub.execute_input":"2023-10-12T01:55:13.137737Z","iopub.status.idle":"2023-10-12T01:55:26.347659Z","shell.execute_reply.started":"2023-10-12T01:55:13.137702Z","shell.execute_reply":"2023-10-12T01:55:26.346087Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.28.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.9.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.98)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.13.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.3.23)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=130431607886eb917eb60b1d55aef16e7433d16ca3d9d50dd63ceb8ac021a698\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence_transformers\nInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import InputExample \nfrom tqdm import tqdm \n\nlang_list = ['it', 'es', 'ar', 'fr', 'de']\n\ntrain_samples = {f'en-{lang}': [] for lang in lang_list}\n\nfor row in tqdm(ted):\n    idx = row['translations']['language'].index('en')\n    source = row['translations']['translation'][idx].strip() \n    for i, lang in enumerate(row['translations']['language']):\n        if lang in lang_list:\n            translation = row['translations']['translation'][i].strip() \n            train_samples[f'en-{lang}'].append(source + '\\t' + translation)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:55:26.349835Z","iopub.execute_input":"2023-10-12T01:55:26.351018Z","iopub.status.idle":"2023-10-12T01:56:11.657134Z","shell.execute_reply.started":"2023-10-12T01:55:26.350964Z","shell.execute_reply":"2023-10-12T01:56:11.656185Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n100%|██████████| 258098/258098 [00:39<00:00, 6478.54it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for lang_pair in train_samples.keys():\n    print(f'{lang_pair}: {len(train_samples[lang_pair])}')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:11.658846Z","iopub.execute_input":"2023-10-12T01:56:11.660006Z","iopub.status.idle":"2023-10-12T01:56:11.665834Z","shell.execute_reply.started":"2023-10-12T01:56:11.659959Z","shell.execute_reply":"2023-10-12T01:56:11.664862Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"en-it: 204503\nen-es: 196026\nen-ar: 214111\nen-fr: 192304\nen-de: 167888\n","output_type":"stream"}]},{"cell_type":"code","source":"source + '\\t' + translation","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:11.667044Z","iopub.execute_input":"2023-10-12T01:56:11.667781Z","iopub.status.idle":"2023-10-12T01:56:11.679612Z","shell.execute_reply.started":"2023-10-12T01:56:11.667748Z","shell.execute_reply":"2023-10-12T01:56:11.678492Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'( Applause )\\t( Applausi )'"},"metadata":{}}]},{"cell_type":"code","source":"import gzip \nimport os\n\nif not os.path.exists('data'):\n    os.mkdir('data')\n    \nfor lang_pair in train_samples.keys():\n    with gzip.open(f'data/ted-train-{lang_pair}.tsv.gz', 'wt', encoding='utf-8') as f:\n        f.write('\\n'.join(train_samples[lang_pair]))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:11.681002Z","iopub.execute_input":"2023-10-12T01:56:11.681907Z","iopub.status.idle":"2023-10-12T01:56:38.113799Z","shell.execute_reply.started":"2023-10-12T01:56:11.681876Z","shell.execute_reply":"2023-10-12T01:56:38.112712Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:38.115191Z","iopub.execute_input":"2023-10-12T01:56:38.115568Z","iopub.status.idle":"2023-10-12T01:56:39.142892Z","shell.execute_reply.started":"2023-10-12T01:56:38.115535Z","shell.execute_reply":"2023-10-12T01:56:39.141846Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d137b544654259a6077e5fcc935604"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ad436c41ab44bee9c8f457616ebf886"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88b885a10ec47039f0f13541af6cffe"}},"metadata":{}}]},{"cell_type":"code","source":"sentences = [\n    'we will include several languages',\n    '一些中文单词',\n    'το ελληνικό αλφάβητο είναι πολύ ωραίο',\n    'ჩვენ გვაქვს ქართული'\n]\n\nfor text in sentences:\n    print(bert_tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:39.148206Z","iopub.execute_input":"2023-10-12T01:56:39.148850Z","iopub.status.idle":"2023-10-12T01:56:39.157480Z","shell.execute_reply.started":"2023-10-12T01:56:39.148810Z","shell.execute_reply":"2023-10-12T01:56:39.156508Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['we', 'will', 'include', 'several', 'languages']\n['一', '[UNK]', '中', '文', '[UNK]', '[UNK]']\n['τ', '##ο', 'ε', '##λ', '##λ', '##η', '##ν', '##ι', '##κ', '##ο', 'α', '##λ', '##φ', '##α', '##β', '##η', '##τ', '##ο', 'ε', '##ι', '##ν', '##α', '##ι', 'π', '##ο', '##λ', '##υ', 'ω', '##ρ', '##α', '##ι', '##ο']\n['[UNK]', '[UNK]', '[UNK]']\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import XLMRobertaTokenizer\n\nxlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:39.158808Z","iopub.execute_input":"2023-10-12T01:56:39.159396Z","iopub.status.idle":"2023-10-12T01:56:40.894653Z","shell.execute_reply.started":"2023-10-12T01:56:39.159363Z","shell.execute_reply":"2023-10-12T01:56:40.893688Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1d14c79c0124e6b8c6600786d70e39d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26310e0671724b309574d2409c3bc371"}},"metadata":{}}]},{"cell_type":"code","source":"for text in sentences:\n    print(xlmr_tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:40.895929Z","iopub.execute_input":"2023-10-12T01:56:40.897087Z","iopub.status.idle":"2023-10-12T01:56:40.903508Z","shell.execute_reply.started":"2023-10-12T01:56:40.897038Z","shell.execute_reply":"2023-10-12T01:56:40.902521Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['▁we', '▁will', '▁include', '▁several', '▁language', 's']\n['▁', '一些', '中文', '单', '词']\n['▁το', '▁ελληνικό', '▁αλ', 'φά', 'βη', 'το', '▁είναι', '▁πολύ', '▁ωραίο']\n['▁ჩვენ', '▁გვაქვს', '▁ქართული']\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import models, SentenceTransformer\n\nxlmr = models.Transformer('xlm-roberta-base')\npooling = models.Pooling(xlmr.get_word_embedding_dimension(), \n                         pooling_mode_mean_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:40.905238Z","iopub.execute_input":"2023-10-12T01:56:40.906113Z","iopub.status.idle":"2023-10-12T01:56:58.305354Z","shell.execute_reply.started":"2023-10-12T01:56:40.906076Z","shell.execute_reply":"2023-10-12T01:56:58.304312Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce115a6a8214caea57307d267271b54"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa54d8735eb437e87059320cbad31b7"}},"metadata":{}}]},{"cell_type":"code","source":"student = SentenceTransformer(modules=[xlmr, pooling])\nstudent","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:58.307117Z","iopub.execute_input":"2023-10-12T01:56:58.307889Z","iopub.status.idle":"2023-10-12T01:56:58.383457Z","shell.execute_reply.started":"2023-10-12T01:56:58.307855Z","shell.execute_reply":"2023-10-12T01:56:58.382389Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"},"metadata":{}}]},{"cell_type":"code","source":"teacher = SentenceTransformer('all-mpnet-base-v2')\nteacher","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:56:58.385248Z","iopub.execute_input":"2023-10-12T01:56:58.386582Z","iopub.status.idle":"2023-10-12T01:57:07.198610Z","shell.execute_reply.started":"2023-10-12T01:56:58.386547Z","shell.execute_reply":"2023-10-12T01:57:07.197338Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ead6d9396d6442cb8091fda0d1377751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"273df3d47a5e451ebefb1bdde892a637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67172990596f4059873ea98e192fd28b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a3e448866e4d8186352da65f0d9699"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f921499bf44d9d99c7d08bbbd827fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"441b4e34229049a4a92b2a5613a6e6ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfd1f5c90df74e33b14617743db679f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb952a0e9354e4a9ca56a3aa103fcd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30e719f0d7ac4f83ad376be12ef6188a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67bc03f8aebf4a47a028eafefab5e807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e81dea9dedb479bacb9e35d84e681b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2616f8bb7174ae4ab718c2cb590824c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbef29a6d9954fdb8f5fb05a27417297"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5148c9d79d48e48632dd9b09ca5de7"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n  (2): Normalize()\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### But here, there is a final normalization layer. We need to avoid outputting normalized embeddings for our student to mimic. So we either remove that normalization layer or use a model without it. The paraphrase models do not use normalization. We’ll use one of those.","metadata":{}},{"cell_type":"code","source":"teacher = SentenceTransformer('paraphrase-distilroberta-base-v2')\nteacher","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:07.200063Z","iopub.execute_input":"2023-10-12T01:57:07.200809Z","iopub.status.idle":"2023-10-12T01:57:14.049333Z","shell.execute_reply.started":"2023-10-12T01:57:07.200767Z","shell.execute_reply":"2023-10-12T01:57:14.048337Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)2b9e5/.gitattributes:   0%|          | 0.00/736 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f9060e83024722ab4dead8ca34f60b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86612b88c7304bfbaafc037029aacfd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)3c1ed2b9e5/README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e384e48de6b1422baf8da6c8f5f78d08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)1ed2b9e5/config.json:   0%|          | 0.00/686 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2485fa5dcb204eb8a5758ea46a89c4b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d110b8ef6a48c1ad8b651dbb960a3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)c1ed2b9e5/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d60ecf6d8546b78b7b8f37908444bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f9197da4d864c3f85254f673370863c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33499e0ba5b54e2f9051df6c9a1073cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea3d6273def4e97b71c21dc69cf9d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)2b9e5/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa9b81a8ec54133bfa566cb57895505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8626a5f71a124826a3f8c7c8aaa1c309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)c1ed2b9e5/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b2ef528b104e16aa755bcee5ef65e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ed2b9e5/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b13e3dbb6a4c5fa803faec2fd6b3e8"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: RobertaModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sentence_transformers import ParallelSentencesDataset\n\ndata = ParallelSentencesDataset(\n    student_model=student, \n    teacher_model=teacher, \n    batch_size=32, \n    use_embedding_cache=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:14.050670Z","iopub.execute_input":"2023-10-12T01:57:14.051550Z","iopub.status.idle":"2023-10-12T01:57:14.060089Z","shell.execute_reply.started":"2023-10-12T01:57:14.051515Z","shell.execute_reply":"2023-10-12T01:57:14.056025Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_files = os.listdir('data')\ntrain_files","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:14.062743Z","iopub.execute_input":"2023-10-12T01:57:14.063634Z","iopub.status.idle":"2023-10-12T01:57:15.136977Z","shell.execute_reply.started":"2023-10-12T01:57:14.063599Z","shell.execute_reply":"2023-10-12T01:57:15.135697Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['ted-train-en-it.tsv.gz',\n 'ted-train-en-ar.tsv.gz',\n 'ted-train-en-de.tsv.gz',\n 'ted-train-en-es.tsv.gz',\n 'ted-train-en-fr.tsv.gz']"},"metadata":{}}]},{"cell_type":"code","source":"for f in train_files:\n    print(f)\n    data.load_data('data/' + f, \n                   max_sentences=250_000, \n                   max_sentence_length=256)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:15.138993Z","iopub.execute_input":"2023-10-12T01:57:15.139963Z","iopub.status.idle":"2023-10-12T01:57:26.436873Z","shell.execute_reply.started":"2023-10-12T01:57:15.139925Z","shell.execute_reply":"2023-10-12T01:57:26.435729Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"ted-train-en-it.tsv.gz\nted-train-en-ar.tsv.gz\nted-train-en-de.tsv.gz\nted-train-en-es.tsv.gz\nted-train-en-fr.tsv.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader \n\nloader = DataLoader(data, shuffle=True, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:26.438317Z","iopub.execute_input":"2023-10-12T01:57:26.438701Z","iopub.status.idle":"2023-10-12T01:57:26.447820Z","shell.execute_reply.started":"2023-10-12T01:57:26.438667Z","shell.execute_reply":"2023-10-12T01:57:26.446810Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers.losses import MSELoss \n\nloss = MSELoss(model=student)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:26.449098Z","iopub.execute_input":"2023-10-12T01:57:26.450570Z","iopub.status.idle":"2023-10-12T01:57:26.654452Z","shell.execute_reply.started":"2023-10-12T01:57:26.450534Z","shell.execute_reply":"2023-10-12T01:57:26.653168Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"student.fit(\n    train_objectives=[(loader, loss)],\n    epochs=1,\n    warmup_steps=int(len(loader) * 0.1),\n    output_path='model1',\n    optimizer_params={'lr': 4e-5, 'eps': 1e-6},\n    save_best_model=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:26.656354Z","iopub.execute_input":"2023-10-12T01:57:26.657145Z","iopub.status.idle":"2023-10-12T01:57:38.221786Z","shell.execute_reply.started":"2023-10-12T01:57:26.657107Z","shell.execute_reply":"2023-10-12T01:57:38.218801Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f99d92f5cbe45c59c9627ec3958fb4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/56489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8441875d6b884409aa061d0af55eac57"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:547: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n  labels = torch.tensor(labels)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstudent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:723\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    721\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_model(features, labels)\n\u001b[1;32m    722\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 723\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    726\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[0;32m---> 76\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import datasets\n\nen = datasets.load_dataset('stsb_multi_mt', 'en', split='test')\nen","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:42.724622Z","iopub.execute_input":"2023-10-12T01:57:42.724995Z","iopub.status.idle":"2023-10-12T01:57:44.953545Z","shell.execute_reply.started":"2023-10-12T01:57:42.724964Z","shell.execute_reply":"2023-10-12T01:57:44.952504Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888d3237fa1d4fad9a4c033d9423e170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"768a95c3a6294084952715bed47b472e"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset stsb_multi_mt/en (download: 1.02 MiB, generated: 1.06 MiB, post-processed: Unknown size, total: 2.08 MiB) to /root/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4573b8dd11444567832c6ebd663c2de8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/229k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5eec9604d54cdc97a5e09237238b3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/74.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81aef616ec9141c6afeef67fc0a2382c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/52.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851464f589dd4ea08c23dc3ff3c28192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset stsb_multi_mt downloaded and prepared to /root/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9. Subsequent calls will reuse this data.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence1', 'sentence2', 'similarity_score'],\n    num_rows: 1379\n})"},"metadata":{}}]},{"cell_type":"code","source":"it = datasets.load_dataset('stsb_multi_mt', 'it', split='test')\nit","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:44.955629Z","iopub.execute_input":"2023-10-12T01:57:44.956229Z","iopub.status.idle":"2023-10-12T01:57:46.817670Z","shell.execute_reply.started":"2023-10-12T01:57:44.956195Z","shell.execute_reply":"2023-10-12T01:57:46.816656Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset stsb_multi_mt/it (download: 1.21 MiB, generated: 1.25 MiB, post-processed: Unknown size, total: 2.46 MiB) to /root/.cache/huggingface/datasets/stsb_multi_mt/it/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c04fb76e36034908b1b36b1cb13311a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/258k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519bf31bbb7845c18a2ce688eea1b705"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/80.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb9c993511d48c0bc0d725b28796912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/58.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c85b742f6d9944b5a0556e15adcd1c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset stsb_multi_mt downloaded and prepared to /root/.cache/huggingface/datasets/stsb_multi_mt/it/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9. Subsequent calls will reuse this data.\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence1', 'sentence2', 'similarity_score'],\n    num_rows: 1379\n})"},"metadata":{}}]},{"cell_type":"code","source":"en[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:46.819358Z","iopub.execute_input":"2023-10-12T01:57:46.820058Z","iopub.status.idle":"2023-10-12T01:57:46.826978Z","shell.execute_reply.started":"2023-10-12T01:57:46.820024Z","shell.execute_reply":"2023-10-12T01:57:46.825999Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'sentence1': 'A girl is styling her hair.',\n 'sentence2': 'A girl is brushing her hair.',\n 'similarity_score': 2.5}"},"metadata":{}}]},{"cell_type":"code","source":"it[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:46.830071Z","iopub.execute_input":"2023-10-12T01:57:46.830832Z","iopub.status.idle":"2023-10-12T01:57:46.838611Z","shell.execute_reply.started":"2023-10-12T01:57:46.830797Z","shell.execute_reply":"2023-10-12T01:57:46.837420Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'sentence1': 'Una ragazza si acconcia i capelli.',\n 'sentence2': 'Una ragazza si sta spazzolando i capelli.',\n 'similarity_score': 2.5}"},"metadata":{}}]},{"cell_type":"code","source":"en = en.map(lambda x: {'similarity_score': x['similarity_score'] / 5.0})\nit = it.map(lambda x: {'similarity_score': x['similarity_score'] / 5.0})\n\nen[0], it[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:46.840585Z","iopub.execute_input":"2023-10-12T01:57:46.841345Z","iopub.status.idle":"2023-10-12T01:57:47.070818Z","shell.execute_reply.started":"2023-10-12T01:57:46.841305Z","shell.execute_reply":"2023-10-12T01:57:47.069847Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1379 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3221d7c3b14543239692a5c639a71bc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1379 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d516d3ac2f8f4d03938d0af8e47e6e28"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"({'sentence1': 'A girl is styling her hair.',\n  'sentence2': 'A girl is brushing her hair.',\n  'similarity_score': 0.5},\n {'sentence1': 'Una ragazza si acconcia i capelli.',\n  'sentence2': 'Una ragazza si sta spazzolando i capelli.',\n  'similarity_score': 0.5})"},"metadata":{}}]},{"cell_type":"code","source":"from sentence_transformers import InputExample\n\nen_samples = []\nit_samples = []\nen_it_samples = []\n\nfor i in range(len(en)):\n    en_samples.append(InputExample(\n        texts=[en[i]['sentence1'], en[i]['sentence2']],\n        label=en[i]['similarity_score']\n    ))\n    it_samples.append(InputExample(\n        texts=[it[i]['sentence1'], it[i]['sentence2']],\n        label=it[i]['similarity_score']\n    ))\n    en_it_samples.append(InputExample(\n        texts=[en[i]['sentence1'], it[i]['sentence2']],\n        label=en[i]['similarity_score']\n    ))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:47.072585Z","iopub.execute_input":"2023-10-12T01:57:47.073334Z","iopub.status.idle":"2023-10-12T01:57:47.721837Z","shell.execute_reply.started":"2023-10-12T01:57:47.073297Z","shell.execute_reply":"2023-10-12T01:57:47.720814Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n\nen_eval = EmbeddingSimilarityEvaluator.from_input_examples(\n    en_samples, write_csv=True\n)\nit_eval = EmbeddingSimilarityEvaluator.from_input_examples(\n    it_samples, write_csv=True\n)\nen_it_eval = EmbeddingSimilarityEvaluator.from_input_examples(\n    en_it_samples, write_csv=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:47.723776Z","iopub.execute_input":"2023-10-12T01:57:47.724501Z","iopub.status.idle":"2023-10-12T01:57:47.733861Z","shell.execute_reply.started":"2023-10-12T01:57:47.724467Z","shell.execute_reply":"2023-10-12T01:57:47.732857Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\n# model = SentenceTransformer('model1')\nmodel = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:57:47.735363Z","iopub.execute_input":"2023-10-12T01:57:47.736063Z","iopub.status.idle":"2023-10-12T01:58:17.417935Z","shell.execute_reply.started":"2023-10-12T01:57:47.736019Z","shell.execute_reply":"2023-10-12T01:58:17.416950Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)9e268/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8563679cec1144c385c0bcddde313b0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdc8f00a92fd4623b5a17c7ed1c19a32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)f2cd19e268/README.md:   0%|          | 0.00/3.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e9cf0f601464064a84788778769bd07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cd19e268/config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb53be91bca4e79af0a0b7f48e62402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6db8ec5540a943b7a3b6d03c4a7e53ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b02938331fec4e86a41339c73fe59efd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2166a04d647447e9b18a312905bd6f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01f5db7dd144f31be9f1bd111ae4947"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea109c32300e43d597a1fe7f689b3676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)9e268/tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82955dc399ba4882b0aeff3329a10bdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef3a814d8efd4d5da35e707f5cadf126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)d19e268/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4c105543b9460386b0a8eb73e5d7ad"}},"metadata":{}}]},{"cell_type":"code","source":"en_eval(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:58:17.419527Z","iopub.execute_input":"2023-10-12T01:58:17.420157Z","iopub.status.idle":"2023-10-12T01:58:21.477110Z","shell.execute_reply.started":"2023-10-12T01:58:17.420121Z","shell.execute_reply":"2023-10-12T01:58:21.476107Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.8682219599128399"},"metadata":{}}]},{"cell_type":"code","source":"it_eval(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:58:21.480074Z","iopub.execute_input":"2023-10-12T01:58:21.480711Z","iopub.status.idle":"2023-10-12T01:58:25.583594Z","shell.execute_reply.started":"2023-10-12T01:58:21.480676Z","shell.execute_reply":"2023-10-12T01:58:25.582539Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.8409392982575622"},"metadata":{}}]},{"cell_type":"code","source":"en_it_eval(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:58:25.585184Z","iopub.execute_input":"2023-10-12T01:58:25.585844Z","iopub.status.idle":"2023-10-12T01:58:29.321759Z","shell.execute_reply.started":"2023-10-12T01:58:25.585805Z","shell.execute_reply":"2023-10-12T01:58:29.320717Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0.8326430915501263"},"metadata":{}}]}]}