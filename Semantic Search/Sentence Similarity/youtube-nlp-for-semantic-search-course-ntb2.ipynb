{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-12T01:16:03.716787Z","iopub.execute_input":"2023-10-12T01:16:03.717466Z","iopub.status.idle":"2023-10-12T01:16:03.727567Z","shell.execute_reply.started":"2023-10-12T01:16:03.717433Z","shell.execute_reply":"2023-10-12T01:16:03.726252Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Video 4  Multiple Negatives Ranking Loss","metadata":{}},{"cell_type":"code","source":"import datasets \n\nsnli = datasets.load_dataset('snli', split='train')\nmnli = datasets.load_dataset('glue', 'mnli', split='train')\nmnli = mnli.remove_columns(['idx'])\nsnli = snli.cast(mnli.features)\n\ndataset = datasets.concatenate_datasets([snli, mnli])","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:16:03.729660Z","iopub.execute_input":"2023-10-12T01:16:03.730519Z","iopub.status.idle":"2023-10-12T01:16:47.260412Z","shell.execute_reply.started":"2023-10-12T01:16:03.730484Z","shell.execute_reply":"2023-10-12T01:16:47.259519Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d287fb53634e1ca17a96d207c075cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/938 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cbf3a6e5c394ed1b4efb889cf1d0f20"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset snli/plain_text (download: 90.17 MiB, generated: 65.51 MiB, post-processed: Unknown size, total: 155.68 MiB) to /root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"401cc898afa546fcb34d885813a53024"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fe276eb16ed438baea8133d88e151c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/65.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8692c2ac347f4fdf89e7dda98ad9149b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c447a604114729b7fc2e2ad0bc7199"}},"metadata":{}},{"name":"stdout","text":"Dataset snli downloaded and prepared to /root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1d01136ddb04b7ca27c9c6cd6b68815"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5daa1287a1ee49309b85db93fffcd2ad"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/313M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1beb3aa9c2e74b09811423a448f0412b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/56 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40567beba2354aeabc91f4ce0f6369b9"}},"metadata":{}}]},{"cell_type":"code","source":"print(f'Before: {len(dataset)} rows')\ndataset = dataset.filter(\n    lambda x: True if x['label'] == 0 else False \n)\nprint(f'After: {len(dataset)} rows')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:16:47.262062Z","iopub.execute_input":"2023-10-12T01:16:47.262816Z","iopub.status.idle":"2023-10-12T01:16:52.372737Z","shell.execute_reply.started":"2023-10-12T01:16:47.262781Z","shell.execute_reply":"2023-10-12T01:16:52.371782Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Before: 942854 rows\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/943 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a9ac868d69843ba89bb5b4412a73bdb"}},"metadata":{}},{"name":"stdout","text":"After: 314315 rows\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer \n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndataset = dataset.map(\n    lambda x: tokenizer(x['premise'], max_length=128, padding='max_length', truncation=True), batched=True\n)\n\ndataset = dataset.rename_column('input_ids', 'anchor_ids')\ndataset = dataset.rename_column('attention_mask', 'anchor_mask')\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:16:52.374170Z","iopub.execute_input":"2023-10-12T01:16:52.374489Z","iopub.status.idle":"2023-10-12T01:19:08.049386Z","shell.execute_reply.started":"2023-10-12T01:16:52.374458Z","shell.execute_reply":"2023-10-12T01:19:08.048374Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3210112e9806499a8a0ae869a0d81121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f467b4a5ff64843947d14791e194fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f28009459b34cebb4e2eac3c41e1538"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/315 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b42efb909d4c59879f0e39f9dabdfd"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['premise', 'hypothesis', 'label', 'anchor_ids', 'token_type_ids', 'anchor_mask'],\n    num_rows: 314315\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.map(\n    lambda x: tokenizer(x['hypothesis'], max_length=128, padding='max_length', truncation=True), batched=True\n)\n\ndataset = dataset.rename_column('input_ids', 'positive_ids')\ndataset = dataset.rename_column('attention_mask', 'positive_mask')\n\ndataset = dataset.remove_columns(['premise', 'hypothesis', 'label', 'token_type_ids'])\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:19:08.051921Z","iopub.execute_input":"2023-10-12T01:19:08.052444Z","iopub.status.idle":"2023-10-12T01:21:26.056725Z","shell.execute_reply.started":"2023-10-12T01:19:08.052419Z","shell.execute_reply":"2023-10-12T01:21:26.055727Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/315 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c22bb5ef199d4776a69db8a5d6e6bf9c"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['anchor_ids', 'anchor_mask', 'positive_ids', 'positive_mask'],\n    num_rows: 314315\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset.set_format(type='torch', output_all_columns=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:26.058154Z","iopub.execute_input":"2023-10-12T01:21:26.058493Z","iopub.status.idle":"2023-10-12T01:21:30.806695Z","shell.execute_reply.started":"2023-10-12T01:21:26.058462Z","shell.execute_reply":"2023-10-12T01:21:30.805690Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch \n\nbatch_size = 32 \n\nloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:30.808079Z","iopub.execute_input":"2023-10-12T01:21:30.808689Z","iopub.status.idle":"2023-10-12T01:21:30.813519Z","shell.execute_reply.started":"2023-10-12T01:21:30.808661Z","shell.execute_reply":"2023-10-12T01:21:30.812607Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"![](https://d33wubrfki0l68.cloudfront.net/03eab5d2ff299fa356d276f145360508faf7e1e0/f5708/images/fine-tuning-sentence-transformers-mnr-loss-2.jpg)","metadata":{}},{"cell_type":"code","source":"from transformers import BertModel \n\nmodel = BertModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:30.814819Z","iopub.execute_input":"2023-10-12T01:21:30.815673Z","iopub.status.idle":"2023-10-12T01:21:47.490327Z","shell.execute_reply.started":"2023-10-12T01:21:30.815640Z","shell.execute_reply":"2023-10-12T01:21:47.489351Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ab0c293bbb443fb5ef5e013f7125da"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"def mean_pool(token_embeds, attention_mask):\n    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float() \n    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n    return pool","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.491916Z","iopub.execute_input":"2023-10-12T01:21:47.492586Z","iopub.status.idle":"2023-10-12T01:21:47.498497Z","shell.execute_reply.started":"2023-10-12T01:21:47.492549Z","shell.execute_reply":"2023-10-12T01:21:47.497198Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"cos_sim = torch.nn.CosineSimilarity() ","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.500006Z","iopub.execute_input":"2023-10-12T01:21:47.500333Z","iopub.status.idle":"2023-10-12T01:21:47.520659Z","shell.execute_reply.started":"2023-10-12T01:21:47.500277Z","shell.execute_reply":"2023-10-12T01:21:47.519845Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"a = torch.randn((32, 768))\np = torch.randn((32, 768))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.524651Z","iopub.execute_input":"2023-10-12T01:21:47.525289Z","iopub.status.idle":"2023-10-12T01:21:47.532818Z","shell.execute_reply.started":"2023-10-12T01:21:47.525252Z","shell.execute_reply":"2023-10-12T01:21:47.531680Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"a.shape, p.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.534534Z","iopub.execute_input":"2023-10-12T01:21:47.535118Z","iopub.status.idle":"2023-10-12T01:21:47.544108Z","shell.execute_reply.started":"2023-10-12T01:21:47.535087Z","shell.execute_reply":"2023-10-12T01:21:47.543168Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(torch.Size([32, 768]), torch.Size([32, 768]))"},"metadata":{}}]},{"cell_type":"code","source":"scores = [] \nfor a_i in a:\n#     print(a_i.shape)\n    scores.append(cos_sim(a_i.reshape(1, a_i.shape[0]), p))\n#     print(a_i.reshape(1, a_i.shape[0]).shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.545249Z","iopub.execute_input":"2023-10-12T01:21:47.546303Z","iopub.status.idle":"2023-10-12T01:21:47.676709Z","shell.execute_reply.started":"2023-10-12T01:21:47.546270Z","shell.execute_reply":"2023-10-12T01:21:47.675773Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"scores = torch.stack(scores)\nscores","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.677971Z","iopub.execute_input":"2023-10-12T01:21:47.678812Z","iopub.status.idle":"2023-10-12T01:21:47.722469Z","shell.execute_reply.started":"2023-10-12T01:21:47.678778Z","shell.execute_reply":"2023-10-12T01:21:47.721539Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0258, -0.0194, -0.0094,  ..., -0.0721, -0.0005, -0.0094],\n        [-0.0090, -0.0113,  0.0246,  ..., -0.0115, -0.0077,  0.0295],\n        [ 0.0381,  0.0102,  0.0553,  ...,  0.0168, -0.0144, -0.0530],\n        ...,\n        [-0.1051, -0.0323,  0.0312,  ...,  0.0350, -0.0179,  0.0571],\n        [ 0.0057, -0.0727, -0.0531,  ..., -0.0394,  0.0700,  0.0325],\n        [-0.0101,  0.0294,  0.0086,  ..., -0.0053, -0.0201, -0.0523]])"},"metadata":{}}]},{"cell_type":"code","source":"scores.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.723769Z","iopub.execute_input":"2023-10-12T01:21:47.724376Z","iopub.status.idle":"2023-10-12T01:21:47.730303Z","shell.execute_reply.started":"2023-10-12T01:21:47.724345Z","shell.execute_reply":"2023-10-12T01:21:47.729313Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 32])"},"metadata":{}}]},{"cell_type":"code","source":"labels = torch.tensor(range(len(scores)), dtype=torch.long, device=scores.device)\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.731581Z","iopub.execute_input":"2023-10-12T01:21:47.732446Z","iopub.status.idle":"2023-10-12T01:21:47.742844Z","shell.execute_reply.started":"2023-10-12T01:21:47.732413Z","shell.execute_reply":"2023-10-12T01:21:47.741963Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"},"metadata":{}}]},{"cell_type":"code","source":"loss_func = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.744093Z","iopub.execute_input":"2023-10-12T01:21:47.744928Z","iopub.status.idle":"2023-10-12T01:21:47.752343Z","shell.execute_reply.started":"2023-10-12T01:21:47.744897Z","shell.execute_reply":"2023-10-12T01:21:47.751474Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"loss_func(scores, labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.753671Z","iopub.execute_input":"2023-10-12T01:21:47.754266Z","iopub.status.idle":"2023-10-12T01:21:47.781500Z","shell.execute_reply.started":"2023-10-12T01:21:47.754226Z","shell.execute_reply":"2023-10-12T01:21:47.780656Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"tensor(3.4680)"},"metadata":{}}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:47.782592Z","iopub.execute_input":"2023-10-12T01:21:47.783345Z","iopub.status.idle":"2023-10-12T01:21:55.386339Z","shell.execute_reply.started":"2023-10-12T01:21:47.783315Z","shell.execute_reply":"2023-10-12T01:21:55.385431Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"scale = 20.0 \ncos_sim.to(device)\nloss_func.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:55.387523Z","iopub.execute_input":"2023-10-12T01:21:55.387857Z","iopub.status.idle":"2023-10-12T01:21:55.394041Z","shell.execute_reply.started":"2023-10-12T01:21:55.387824Z","shell.execute_reply":"2023-10-12T01:21:55.393165Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CrossEntropyLoss()"},"metadata":{}}]},{"cell_type":"code","source":"from transformers.optimization import get_linear_schedule_with_warmup\n\noptim = torch.optim.Adam(model.parameters(), lr=2e-5)\ntotal_steps = int(len(dataset) / batch_size)\nwarmup_steps = int(0.1 * total_steps)\nscheduler = get_linear_schedule_with_warmup(\n    optim, num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps - warmup_steps\n)\nepochs = 1","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:55.395281Z","iopub.execute_input":"2023-10-12T01:21:55.396330Z","iopub.status.idle":"2023-10-12T01:21:55.410760Z","shell.execute_reply.started":"2023-10-12T01:21:55.396289Z","shell.execute_reply":"2023-10-12T01:21:55.409896Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm \n\nfor epoch in range(epochs):\n    model.train() \n    loop = tqdm(loader, leave=True)\n    for batch in loop:\n        optim.zero_grad() \n        anchor_ids = batch['anchor_ids'].to(device)\n        anchor_mask = batch['anchor_mask'].to(device)\n        pos_ids = batch['positive_ids'].to(device)\n        pos_mask = batch['positive_mask'].to(device)\n        \n        a = model(anchor_ids, attention_mask=anchor_mask)[0] \n        p = model(pos_ids, attention_mask=pos_mask)[0] \n        a = mean_pool(a, anchor_mask)\n        p = mean_pool(p, pos_mask)\n        \n        scores = torch.stack([cos_sim(a_i.reshape(1, a_i.shape[0]), p) for a_i in a])\n        labels = torch.tensor(range(len(scores)), dtype=torch.long, device=scores.device)\n        loss = loss_func(scores * scale, labels)\n        loss.backward() \n        optim.step() \n        scheduler.step() \n        \n        loop.set_description(f'Epoch {epoch + 1}')\n        loop.set_postfix(loss=loss.item())","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:21:55.411854Z","iopub.execute_input":"2023-10-12T01:21:55.412782Z","iopub.status.idle":"2023-10-12T01:46:38.851437Z","shell.execute_reply.started":"2023-10-12T01:21:55.412752Z","shell.execute_reply":"2023-10-12T01:46:38.849364Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Epoch 1:  12%|█▏        | 1224/9823 [24:43<2:53:39,  1.21s/it, loss=1.45] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scores)), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(scores \u001b[38;5;241m*\u001b[39m scale, labels)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     22\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep() \n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep() \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import os \n\nmodel_path = 'model1'\n\nif not os.path.exists(model_path):\n    os.mkdir(model_path)\n\nmodel.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:46:44.177930Z","iopub.execute_input":"2023-10-12T01:46:44.178296Z","iopub.status.idle":"2023-10-12T01:46:44.955995Z","shell.execute_reply.started":"2023-10-12T01:46:44.178266Z","shell.execute_reply":"2023-10-12T01:46:44.954880Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"snli = datasets.load_dataset('snli', split='train')\nmnli = datasets.load_dataset('glue', 'mnli', split='train')\nmnli = mnli.remove_columns(['idx'])\nsnli = snli.cast(mnli.features)\n\ndataset = datasets.concatenate_datasets([snli, mnli])","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:46:44.958043Z","iopub.execute_input":"2023-10-12T01:46:44.958674Z","iopub.status.idle":"2023-10-12T01:46:47.344975Z","shell.execute_reply.started":"2023-10-12T01:46:44.958636Z","shell.execute_reply":"2023-10-12T01:46:47.344098Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/56 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a7904163c948adb4862347e2854dfd"}},"metadata":{}}]},{"cell_type":"code","source":"print(f'Before: {len(dataset)} rows')\ndataset = dataset.filter(\n    lambda x: True if x['label'] == 0 else False \n)\nprint(f'After: {len(dataset)} rows')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:46:47.346295Z","iopub.execute_input":"2023-10-12T01:46:47.346929Z","iopub.status.idle":"2023-10-12T01:46:52.658958Z","shell.execute_reply.started":"2023-10-12T01:46:47.346896Z","shell.execute_reply":"2023-10-12T01:46:52.658020Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Before: 942854 rows\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/943 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a6b55b2037467984f2023a8944f583"}},"metadata":{}},{"name":"stdout","text":"After: 314315 rows\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:46:52.661531Z","iopub.execute_input":"2023-10-12T01:46:52.661836Z","iopub.status.idle":"2023-10-12T01:47:07.139532Z","shell.execute_reply.started":"2023-10-12T01:46:52.661811Z","shell.execute_reply":"2023-10-12T01:47:07.138435Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m306.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.28.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.9.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.98)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.13.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.11.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.3.23)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=dac67ab71f7d1fef421187a22395a356d0e9c7137037930241a5f34b196fa645\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence_transformers\nInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import InputExample \n\ntrain_samples = [] \n\nfor row in tqdm(dataset):\n    train_samples.append(InputExample(texts=[row['premise'], row['hypothesis']]))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:47:07.141224Z","iopub.execute_input":"2023-10-12T01:47:07.141581Z","iopub.status.idle":"2023-10-12T01:47:33.291167Z","shell.execute_reply.started":"2023-10-12T01:47:07.141537Z","shell.execute_reply":"2023-10-12T01:47:33.290229Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 314315/314315 [00:24<00:00, 12889.64it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import datasets \n\nbatch_size = 32 \n\nloader = datasets.NoDuplicatesDataLoader(train_samples, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:47:33.292788Z","iopub.execute_input":"2023-10-12T01:47:33.293435Z","iopub.status.idle":"2023-10-12T01:47:33.470038Z","shell.execute_reply.started":"2023-10-12T01:47:33.293400Z","shell.execute_reply":"2023-10-12T01:47:33.469143Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import models, SentenceTransformer\n\nbert = models.Transformer('bert-base-uncased')\npooler = models.Pooling(bert.get_word_embedding_dimension(), pooling_mode_mean_tokens=True)\n\nmodel = SentenceTransformer(modules=[bert, pooler])\n\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:47:33.471325Z","iopub.execute_input":"2023-10-12T01:47:33.472239Z","iopub.status.idle":"2023-10-12T01:47:36.450802Z","shell.execute_reply.started":"2023-10-12T01:47:33.472204Z","shell.execute_reply":"2023-10-12T01:47:36.449851Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b593a973fe43f2a0ef12c10755de33"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sentence_transformers import losses \n\nloss = losses.MultipleNegativesRankingLoss(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:47:36.452272Z","iopub.execute_input":"2023-10-12T01:47:36.452608Z","iopub.status.idle":"2023-10-12T01:47:36.463159Z","shell.execute_reply.started":"2023-10-12T01:47:36.452575Z","shell.execute_reply":"2023-10-12T01:47:36.462292Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"epochs = 1 \nwarmup_steps = int(len(loader) * epochs * 0.1)\n\nmodel.fit(\n    train_objectives=[(loader, loss)],\n    epochs=epochs,\n    warmup_steps=warmup_steps,\n    output_path='model2',\n    show_progress_bar=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:47:36.464738Z","iopub.execute_input":"2023-10-12T01:47:36.465376Z","iopub.status.idle":"2023-10-12T01:48:01.720596Z","shell.execute_reply.started":"2023-10-12T01:47:36.465342Z","shell.execute_reply":"2023-10-12T01:48:01.718783Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820272996f594c9cab18bb1d48d29bfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/9822 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec49b8b07fc459b8b82f5c0fc1228f9"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m      2\u001b[0m warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loader) \u001b[38;5;241m*\u001b[39m epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:722\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_model(features, labels)\n\u001b[0;32m--> 722\u001b[0m     \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(loss_model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n\u001b[1;32m    724\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import datasets\n\nsts = datasets.load_dataset('glue', 'stsb', split='validation')\nsts","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:48:06.262837Z","iopub.execute_input":"2023-10-12T01:48:06.263728Z","iopub.status.idle":"2023-10-12T01:48:07.829865Z","shell.execute_reply.started":"2023-10-12T01:48:06.263662Z","shell.execute_reply":"2023-10-12T01:48:07.828982Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset glue/stsb (download: 784.05 KiB, generated: 1.09 MiB, post-processed: Unknown size, total: 1.86 MiB) to /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/803k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c25a1a8c133444dbfffd031b28fb151"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence1', 'sentence2', 'label', 'idx'],\n    num_rows: 1500\n})"},"metadata":{}}]},{"cell_type":"code","source":"sts = sts.map(lambda x: {'label': x['label'] / 5.0})","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:48:07.834161Z","iopub.execute_input":"2023-10-12T01:48:07.836189Z","iopub.status.idle":"2023-10-12T01:48:08.047972Z","shell.execute_reply.started":"2023-10-12T01:48:07.836153Z","shell.execute_reply":"2023-10-12T01:48:08.047004Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1500 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2f5fc53aa44ca8ab2a1f8aef3b36b7"}},"metadata":{}}]},{"cell_type":"code","source":"from sentence_transformers import InputExample\n\nsamples = []\nfor sample in sts:\n    samples.append(InputExample(\n        texts=[sample['sentence1'], sample['sentence2']],\n        label=sample['label']\n    ))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:48:08.051721Z","iopub.execute_input":"2023-10-12T01:48:08.053706Z","iopub.status.idle":"2023-10-12T01:48:08.215070Z","shell.execute_reply.started":"2023-10-12T01:48:08.053673Z","shell.execute_reply":"2023-10-12T01:48:08.214216Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n\nevaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n    samples, write_csv=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:48:08.219581Z","iopub.execute_input":"2023-10-12T01:48:08.221544Z","iopub.status.idle":"2023-10-12T01:48:08.228373Z","shell.execute_reply.started":"2023-10-12T01:48:08.221511Z","shell.execute_reply":"2023-10-12T01:48:08.227345Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('model2')\n\nevaluator(model)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T01:48:08.232415Z","iopub.execute_input":"2023-10-12T01:48:08.234719Z","iopub.status.idle":"2023-10-12T01:48:09.637360Z","shell.execute_reply.started":"2023-10-12T01:48:08.234685Z","shell.execute_reply":"2023-10-12T01:48:09.634853Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:259\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/sentence-transformers/model2","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m evaluator(model)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     83\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# Download from hub with caching\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mignore_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflax_model.msgpack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrust_model.ot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(model_path)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/util.py:442\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m use_auth_token:\n\u001b[1;32m    440\u001b[0m     token \u001b[38;5;241m=\u001b[39m HfFolder\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[0;32m--> 442\u001b[0m model_info \u001b[38;5;241m=\u001b[39m \u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m storage_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    445\u001b[0m     cache_dir, repo_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    446\u001b[0m )\n\u001b[1;32m    448\u001b[0m all_files \u001b[38;5;241m=\u001b[39m model_info\u001b[38;5;241m.\u001b[39msiblings\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:1624\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 1624\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:291\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# 401 is misleading as it is returned for:\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m#    - private and gated repos if user is not authenticated\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m#    - missing repos\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    294\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m     )\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-65275058-3aabb36c5b58333c7c1e1bf8)\n\nRepository Not Found for url: https://huggingface.co/api/models/sentence-transformers/model2.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."],"ename":"RepositoryNotFoundError","evalue":"401 Client Error. (Request ID: Root=1-65275058-3aabb36c5b58333c7c1e1bf8)\n\nRepository Not Found for url: https://huggingface.co/api/models/sentence-transformers/model2.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","output_type":"error"}]}]}