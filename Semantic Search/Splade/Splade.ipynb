{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yve02M4Q2x1",
        "outputId": "e0c68b3f-438f-45f8-c14a-5642a005e521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers) (1.3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"naver/splade-cocondenser-ensembledistil\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "CeTvrxo4RXLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I love Python very much because it is a very interesting computer language\"\n",
        "\n",
        "tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "output = model(**tokens)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw1yFbFmRqDz",
        "outputId": "7fdb26ea-ff1e-4b16-f4af-b4d3131d7728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskedLMOutput(loss=None, logits=tensor([[[ -6.1202,  -8.3422,  -7.6260,  ...,  -7.6751,  -7.9525,  -6.1075],\n",
              "         [ -6.7719,  -8.9798,  -7.8527,  ...,  -8.3719,  -8.6289,  -6.6373],\n",
              "         [ -9.3684, -10.5532,  -9.2008,  ...,  -9.6652,  -9.8406,  -8.1002],\n",
              "         ...,\n",
              "         [ -6.8283,  -8.5560,  -8.3984,  ...,  -8.6114,  -8.3427,  -6.3242],\n",
              "         [ -6.7843,  -8.5415,  -8.5728,  ...,  -8.4019,  -8.2313,  -6.7143],\n",
              "         [-21.3627, -17.6899, -16.6674,  ..., -17.5429, -16.4934, -18.7595]]],\n",
              "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHkSuErvSCnV",
        "outputId": "07e5a8fb-4952-4807-a8a0-2b7981068ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 15, 30522])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "vec = torch.max(torch.log(1 + torch.relu(output.logits)) * tokens[\"attention_mask\"].unsqueeze(-1), dim=1)[0].squeeze()\n",
        "vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SihO1rMSFul",
        "outputId": "38b935f4-841f-4670-ee54-a75356137dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30522])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGPpvQTiShr1",
        "outputId": "46f9842d-309e-4295-9fea-a4d78ceba08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = vec.nonzero().squeeze().cpu().tolist()\n",
        "print(len(cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeNZ2ORvSjHj",
        "outputId": "926e2c95-3e37-4f9b-8c7e-06db59a3f467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = vec[cols].cpu().tolist()\n",
        "sparse_dict = dict(zip(cols, weights))\n",
        "sparse_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgdo3fpmSqcT",
        "outputId": "c6984619-6d5e-4f8b-c0ee-4d99d4eb77bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1045: 0.3497620224952698,\n",
              " 1052: 0.45730113983154297,\n",
              " 2009: 0.34368041157722473,\n",
              " 2061: 0.07585734128952026,\n",
              " 2138: 0.9671566486358643,\n",
              " 2172: 0.2688765525817871,\n",
              " 2190: 0.2166033685207367,\n",
              " 2200: 0.8433794379234314,\n",
              " 2204: 0.553397536277771,\n",
              " 2293: 1.1777918338775635,\n",
              " 2428: 0.31924358010292053,\n",
              " 2653: 1.2211918830871582,\n",
              " 2748: 0.355165958404541,\n",
              " 2759: 0.2548351287841797,\n",
              " 2978: 0.2851647138595581,\n",
              " 3112: 0.28132161498069763,\n",
              " 3213: 0.006266824435442686,\n",
              " 3274: 1.1782046556472778,\n",
              " 3342: 0.18472643196582794,\n",
              " 3407: 0.3151716887950897,\n",
              " 3835: 0.41453754901885986,\n",
              " 3889: 0.21852819621562958,\n",
              " 3894: 0.15836818516254425,\n",
              " 4007: 0.5925108790397644,\n",
              " 4037: 0.13534662127494812,\n",
              " 4083: 0.40074968338012695,\n",
              " 4132: 0.0072813136503100395,\n",
              " 4155: 1.3275483846664429,\n",
              " 4553: 0.2317194938659668,\n",
              " 4569: 0.13223373889923096,\n",
              " 4669: 0.2612866461277008,\n",
              " 4730: 0.2721441388130188,\n",
              " 4913: 0.15388791263103485,\n",
              " 5186: 0.027692044153809547,\n",
              " 5202: 0.11551856994628906,\n",
              " 5440: 0.13425996899604797,\n",
              " 5454: 0.05027538537979126,\n",
              " 5875: 1.602970004081726,\n",
              " 6108: 0.04217156395316124,\n",
              " 6179: 0.45238828659057617,\n",
              " 6217: 0.15206821262836456,\n",
              " 6581: 0.08553652465343475,\n",
              " 6609: 0.05307326093316078,\n",
              " 6754: 0.3225594460964203,\n",
              " 6890: 0.05035881698131561,\n",
              " 7441: 0.005762393586337566,\n",
              " 7473: 0.7009736895561218,\n",
              " 7488: 1.3273123502731323,\n",
              " 7588: 0.7191295623779297,\n",
              " 8404: 0.019542885944247246,\n",
              " 8957: 0.21233437955379486,\n",
              " 9262: 0.6845235824584961,\n",
              " 10000: 0.15611056983470917,\n",
              " 11603: 0.3562265932559967,\n",
              " 15489: 0.12995395064353943,\n",
              " 17160: 0.04978621378540993,\n",
              " 18001: 0.41225379705429077,\n",
              " 18750: 2.703078031539917}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2token = {idx: token for token, idx in tokenizer.get_vocab().items()}"
      ],
      "metadata": {
        "id": "wdx5HecwS9KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_dict_tokens = {idx2token[idx]: round(weight, 2) for idx, weight in zip(cols, weights)}\n",
        "\n",
        "sparse_dict_tokens = {\n",
        "    k: v for k, v in sorted(\n",
        "        sparse_dict_tokens.items(),\n",
        "        key=lambda item: item[1],\n",
        "        reverse=True\n",
        "    )\n",
        "}\n",
        "\n",
        "sparse_dict_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUSdJPE-TMPj",
        "outputId": "00a5c721-de68-40d3-8d41-6dcaf73cca1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'python': 2.7,\n",
              " 'interesting': 1.6,\n",
              " 'languages': 1.33,\n",
              " 'snake': 1.33,\n",
              " 'language': 1.22,\n",
              " 'love': 1.18,\n",
              " 'computer': 1.18,\n",
              " 'because': 0.97,\n",
              " 'very': 0.84,\n",
              " 'computers': 0.72,\n",
              " 'pc': 0.7,\n",
              " 'java': 0.68,\n",
              " 'software': 0.59,\n",
              " 'good': 0.55,\n",
              " 'p': 0.46,\n",
              " 'useful': 0.45,\n",
              " 'nice': 0.41,\n",
              " 'fuzzy': 0.41,\n",
              " 'learning': 0.4,\n",
              " 'yes': 0.36,\n",
              " 'linux': 0.36,\n",
              " 'i': 0.35,\n",
              " 'it': 0.34,\n",
              " 'really': 0.32,\n",
              " 'happy': 0.32,\n",
              " 'greg': 0.32,\n",
              " 'bit': 0.29,\n",
              " 'success': 0.28,\n",
              " 'much': 0.27,\n",
              " 'programming': 0.27,\n",
              " 'liked': 0.26,\n",
              " 'popular': 0.25,\n",
              " 'learn': 0.23,\n",
              " 'best': 0.22,\n",
              " 'steve': 0.22,\n",
              " 'robot': 0.21,\n",
              " 'remember': 0.18,\n",
              " 'magic': 0.16,\n",
              " 'raven': 0.16,\n",
              " 'dave': 0.15,\n",
              " 'popularity': 0.15,\n",
              " 'website': 0.14,\n",
              " 'fun': 0.13,\n",
              " 'favorite': 0.13,\n",
              " 'font': 0.13,\n",
              " 'dragon': 0.12,\n",
              " 'excellent': 0.09,\n",
              " 'so': 0.08,\n",
              " 'choose': 0.05,\n",
              " 'terry': 0.05,\n",
              " 'perry': 0.05,\n",
              " 'fascinating': 0.05,\n",
              " 'jay': 0.04,\n",
              " 'extremely': 0.03,\n",
              " 'happiness': 0.02,\n",
              " 'writer': 0.01,\n",
              " 'platform': 0.01,\n",
              " 'jeremy': 0.01}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/naver/splade.git\n",
        "from splade.models.transformer_rep import Splade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkOP2XeIUzC9",
        "outputId": "22c1602b-1ec2-4489-ba39-0e754c251d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/naver/splade.git\n",
            "  Cloning https://github.com/naver/splade.git to /tmp/pip-req-build-wbpth80s\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/naver/splade.git /tmp/pip-req-build-wbpth80s\n",
            "  Resolved https://github.com/naver/splade.git to commit 3781228d5f07e7a6ae14a479e469a715de79e976\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers==4.18.0 in /usr/local/lib/python3.10/dist-packages (from SPLADE==2.1) (4.18.0)\n",
            "Requirement already satisfied: omegaconf==2.1.2 in /usr/local/lib/python3.10/dist-packages (from SPLADE==2.1) (2.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.2->SPLADE==2.1) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.2->SPLADE==2.1) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0->SPLADE==2.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0->SPLADE==2.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0->SPLADE==2.1) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0->SPLADE==2.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0->SPLADE==2.1) (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_model_id = \"naver/splade-cocondenser-ensembledistil\"\n",
        "\n",
        "sparse_model = Splade(sparse_model_id, agg=\"max\")\n",
        "sparse_model.eval()"
      ],
      "metadata": {
        "id": "90SJQjDYU8zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    sparse_emb = sparse_model(d_kwargs=tokens)[\"d_rep\"].squeeze()\n",
        "\n",
        "sparse_emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DuEmNVdVtLF",
        "outputId": "a46bc9af-e17a-4f00-eb5a-052b9459da53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30522])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "   \"Programmed cell death (PCD) is the regulated death of cells within an organism\",\n",
        "   \"How is the scheduled death of cells within a living thing regulated?\",\n",
        "   \"Photosynthesis is the process of storing light energy as chemical energy in cells\"\n",
        "]"
      ],
      "metadata": {
        "id": "WqBZ01tbWl_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(\n",
        "    texts,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "output = model(**tokens)\n",
        "\n",
        "vecs = torch.max(torch.log(1 + torch.relu(output.logits)) * tokens[\"attention_mask\"].unsqueeze(-1), dim=1)[0].squeeze().detach().cpu().numpy()\n",
        "vecs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJhyuXACWm4C",
        "outputId": "99f969b5-942e-440a-acc8-3602334bac0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 30522)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sim = np.zeros((vecs.shape[0], vecs.shape[0]))\n",
        "\n",
        "for i, vec in enumerate(vecs):\n",
        "    sim[i,:] = np.dot(vec, vecs.T) / (np.linalg.norm(vec) * np.linalg.norm(vecs, axis=1))\n",
        "\n",
        "sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tzdBrn-XLAi",
        "outputId": "a5822fed-23f0-4852-82a7-930a9a5b0f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999988, 0.54609394, 0.20535833],\n",
              "       [0.54609394, 1.        , 0.20411888],\n",
              "       [0.20535833, 0.20411888, 1.00000012]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}