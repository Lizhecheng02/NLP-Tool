{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify as md\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "def printOutput(output):\n",
    "    print(json.dumps(output, sort_keys=True, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = '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'\n",
    "serpapi_api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_schema = Object(\n",
    "    id='person',\n",
    "    description='Personal information about a person',\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id='first_name',\n",
    "            description='The first name of a person'\n",
    "        )\n",
    "    ],\n",
    "    examples=[\n",
    "        ('Alice and Bob are friends', [{'first_name': 'Alice'}, {'first_name': 'Bob'}])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_extraction_chain(llm, person_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"person\": [\n",
      "      {\n",
      "         \"first_name\": \"Bobby\"\n",
      "      },\n",
      "      {\n",
      "         \"first_name\": \"Rachel\"\n",
      "      },\n",
      "      {\n",
      "         \"first_name\": \"Joe\"\n",
      "      }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "    My name is Bobby.\n",
    "    My sister's name is Rachel.\n",
    "    My brother's name Joe. My dog's name is Spot\n",
    "\"\"\"\n",
    "\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "\n",
    "printOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"person\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = chain.predict_and_parse(text=('The dog went to the park'))['data']\n",
    "printOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_schema = Object(\n",
    "    id='plant',\n",
    "    description='Information about a plant',\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id='plant_type',\n",
    "            description='The common name of the plant'\n",
    "        ),\n",
    "        Text(\n",
    "            id='color',\n",
    "            description='The color of the plant'\n",
    "        ),\n",
    "        Number(\n",
    "            id='rating',\n",
    "            description='The rating of the plant'\n",
    "        )\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            'Roses are red, lilies are white and a 8 out of 10',\n",
    "            [\n",
    "                {'plant_type': 'Roses', 'color': 'red'},\n",
    "                {'plant_type': 'Lily', 'color': 'white', 'rating': 8}\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"plant\": [\n",
      "      {\n",
      "         \"color\": \"brown\",\n",
      "         \"plant_type\": \"Palm trees\",\n",
      "         \"rating\": \"6.0\"\n",
      "      },\n",
      "      {\n",
      "         \"color\": \"green\",\n",
      "         \"plant_type\": \"Sequoia trees\",\n",
      "         \"rating\": \"\"\n",
      "      }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = 'Palm trees are brown with a 6 rating. Sequoia trees are green'\n",
    "\n",
    "chain = create_extraction_chain(llm, plant_schema)\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "\n",
    "printOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = Object(\n",
    "    id='parts',\n",
    "    description='A single part of a car',\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id='part', description='The name of the part'\n",
    "        )\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            'the jeep has wheels and windows',\n",
    "            [\n",
    "                {'part': 'wheel'},\n",
    "                {'part': 'window'}\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "cars_schema = Object(\n",
    "    id='car',\n",
    "    description='Information about a car',\n",
    "    examples=[\n",
    "        (\n",
    "            'the bmw is red and has an engine and steering wheel',\n",
    "            [\n",
    "                {'type': 'BMW', 'color': 'red', 'parts': ['engine', 'steering wheel']}\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id='type',\n",
    "            description='The make or brand of the car'\n",
    "        ),\n",
    "        Text(\n",
    "            id='color',\n",
    "            description='The color of the car'\n",
    "        ),\n",
    "        parts\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"car\": {\n",
      "      \"color\": \"blue\",\n",
      "      \"parts\": [\n",
      "         {\n",
      "            \"part\": \"rear view mirror\"\n",
      "         },\n",
      "         {\n",
      "            \"part\": \"roof\"\n",
      "         },\n",
      "         {\n",
      "            \"part\": \"windshield\"\n",
      "         }\n",
      "      ],\n",
      "      \"type\": \"jeep\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = 'The blue jeep has rear view mirror, roof, windshield'\n",
    "\n",
    "chain = create_extraction_chain(\n",
    "    llm, cars_schema, encoder_or_encoder_class='json')\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "\n",
    "printOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
      "\n",
      "```TypeScript\n",
      "\n",
      "car: { // Information about a car\n",
      " type: string // The make or brand of the car\n",
      " color: string // The color of the car\n",
      " parts: { // A single part of a car\n",
      "  part: string // The name of the part\n",
      " }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "Please output the extracted information in JSON format. Do not output anything except for the extracted information. Do not add any clarifying information. Do not add any fields that are not in the schema. If the text contains attributes that do not appear in the schema, please ignore them. All output must be in JSON format and follow the schema specified above. Wrap the JSON in <json> tags.\n",
      "\n",
      "\n",
      "\n",
      "Input: the bmw is red and has an engine and steering wheel\n",
      "Output: <json>{\"car\": [{\"type\": \"BMW\", \"color\": \"red\", \"parts\": [\"engine\", \"steering wheel\"]}]}</json>\n",
      "Input: the jeep has wheels and windows\n",
      "Output: <json>{\"car\": {\"parts\": [{\"part\": \"wheel\"}, {\"part\": \"window\"}]}}</json>\n",
      "Input: The blue jeep has rear view mirror, roof, windshield\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "prompt = chain.prompt.format_prompt(text=text).to_string()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Object(\n",
    "    id=\"forecaster\",\n",
    "    description=(\n",
    "        \"User is controling an app that makes financial forecasts. \"\n",
    "        \"They will give a command to update a forecast in the future\"\n",
    "    ),\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"year\",\n",
    "            description=\"Year the user wants to update\",\n",
    "            examples=[(\"please increase 2014's customers by 15%\", \"2014\")],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"metric\",\n",
    "            description=\"The unit or metric a user would like to influence\",\n",
    "            examples=[(\"please increase 2014's customers by 15%\", \"customers\")],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"amount\",\n",
    "            description=\"The quantity of a forecast adjustment\",\n",
    "            examples=[(\"please increase 2014's customers by 15%\", \".15\")],\n",
    "            many=True,\n",
    "        )\n",
    "    ],\n",
    "    many=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-RoeWzfsGX1BMb27fi9TWyy1L on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"forecaster\": {\n",
      "      \"amount\": [\n",
      "         \"15\"\n",
      "      ],\n",
      "      \"metric\": [\n",
      "         \"units sold\"\n",
      "      ],\n",
      "      \"year\": [\n",
      "         \"2023\"\n",
      "      ]\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n",
    "output = chain.predict_and_parse(text='please add 15 more units sold to 2023')['data']\n",
    "\n",
    "printOutput(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2000, \n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_from_greenhouse(board_token):\n",
    "    url = f'https://boards-api.greenhouse.io/v1/boards/{board_token}/jobs?content=true'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        print('Whoops, error')\n",
    "        return \n",
    "    status_code = response.status_code \n",
    "    jobs = response.json()['jobs']\n",
    "    print(f'{board_token}: {status_code}, Found {len(jobs)} jobs')\n",
    "    return jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whoops, error\n"
     ]
    }
   ],
   "source": [
    "jobs = pull_from_greenhouse('okta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m job_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPreview:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(json\u001b[39m.\u001b[39mdumps(jobs[job_index])[:\u001b[39m400\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "job_index = 0\n",
    "\n",
    "print('Preview:\\n')\n",
    "print(json.dumps(jobs[job_index])[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describeJob(job_description):\n",
    "    print(f\"Job ID: {job_description['id']}\")\n",
    "    print(f\"Link: {job_description['absolute_url']}\")\n",
    "    print(f\"Updated At: {datetime.fromisoformat(job_description['updated_at'])}\")\n",
    "    print(f\"Title: {job_description['title']}\\n\")\n",
    "    print(f\"Content:\\n{job_description['content'][:550]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 4858786\n",
      "Link: https://www.okta.com/company/careers/opportunity/4858786?gh_jid=4858786\n",
      "Updated At: 2023-05-12 11:53:14-04:00\n",
      "Title: Anaplan Manager\n",
      "\n",
      "Content:\n",
      "&lt;div class=&quot;content-intro&quot;&gt;&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;strong&gt;Get to know Okta&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;\n",
      "&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;br&gt;&lt;/span&gt;Okta is The World’s Identity Company. We free everyone to safely use any technology—anywhere, on any device or app. Our Workforce and Customer Identity Clouds enable secure yet flexible access, authentication, and automation that transforms how people move through the digital world, putting Identity at t\n"
     ]
    }
   ],
   "source": [
    "job_id = 4858786\n",
    "\n",
    "job_description = [item for item in jobs if item['id'] == job_id][0]\n",
    "    \n",
    "describeJob(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(job_description['content'], 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Get to know Okta**\n",
      "\n",
      "\n",
      "  \n",
      "Okta is The World’s Identity Company. We free everyone to safely use any technology—anywhere, on any device or app. Our Workforce and Customer Identity Clouds enable secure yet flexible access, authentication, and automation that transforms how people move through the digital world, putting Identity at the heart of business security and growth.   \n",
      "  \n",
      "At Okta, we celebrate a variety of perspectives and experiences. We are not looking for someone who checks every single box, we’re looking for lifelong learners and people who can make us better with their unique experien\n"
     ]
    }
   ],
   "source": [
    "text = soup.get_text() \n",
    "text = md(text)\n",
    "print(text[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Object(\n",
    "    id='tools',\n",
    "    description=\"\"\"\n",
    "        A tool, application, or other company that is listed in a job description.\n",
    "        Analytics, eCommerce and GTM are not tools\n",
    "    \"\"\",\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id='tool',\n",
    "            description='The name of a tool or company'\n",
    "        )\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            'Experience in working with Netsuite, or Looker a plus',\n",
    "            [\n",
    "                {'tool': 'Netsuite'},\n",
    "                {'tool': 'Looker'}\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            'Experience with Microsoft Excel',\n",
    "            [\n",
    "                {'tool': 'Microsoft Excel'}\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            'You must know AWS to do well in the job',\n",
    "            [\n",
    "                {'tool': 'AWS'}\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            'Troubleshooting customer issues and debugging from logs (Splunk, Syslogs, etc.)',\n",
    "            [\n",
    "                {'tool': 'Splunk'}\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    many=True\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"tools\": [\n",
      "      {\n",
      "         \"tool\": \"Anaplan\"\n",
      "      },\n",
      "      {\n",
      "         \"tool\": \"Hyperion\"\n",
      "      },\n",
      "      {\n",
      "         \"tool\": \"Tableau\"\n",
      "      }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = create_extraction_chain(llm, tools, input_formatter='triple_quotes')\n",
    "\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "printOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_range = Object(\n",
    "    id='salary_range',\n",
    "    description=\"\"\"\n",
    "        The range of salary offered for a job mentioned in a job description\n",
    "    \"\"\",\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id='low_end',\n",
    "            description='The low end of a salary range'\n",
    "        ),\n",
    "        Number(\n",
    "            id='high_end',\n",
    "            description='The high end of a salary range'\n",
    "        )\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            'This position will make between $140 thousand and $230,000.00',\n",
    "            [\n",
    "                {'low_end': 140000, 'high_end': 230000},\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okta: 200, Found 149 jobs\n"
     ]
    }
   ],
   "source": [
    "jobs = pull_from_greenhouse('okta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 4858786\n",
      "Link: https://www.okta.com/company/careers/opportunity/4858786?gh_jid=4858786\n",
      "Updated At: 2023-05-12 11:53:14-04:00\n",
      "Title: Anaplan Manager\n",
      "\n",
      "Content:\n",
      "&lt;div class=&quot;content-intro&quot;&gt;&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;strong&gt;Get to know Okta&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;\n",
      "&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;br&gt;&lt;/span&gt;Okta is The World’s Identity Company. We free everyone to safely use any technology—anywhere, on any device or app. Our Workforce and Customer Identity Clouds enable secure yet flexible access, authentication, and automation that transforms how people move through the digital world, putting Identity at t\n",
      "**Get to know Okta**\n",
      "\n",
      "\n",
      "  \n",
      "Okta is The World’s Identity Company. We free everyone to safely use any technology—anywhere, on any device or app. Our Workforce and Customer Identity Clouds enable secure yet flexible access, authentication, and automation that transforms how people move through the digital world, putting Identity at the heart of business security and growth.   \n",
      "  \n",
      "At Okta, we celebrate a variety of perspectives and experiences. We are not looking for someone who checks every single box, we’re looking for lifelong learners and people who can make us better with their unique experien\n"
     ]
    }
   ],
   "source": [
    "job_id = 4858786\n",
    "\n",
    "job_description = [item for item in jobs if item['id'] == job_id][0]\n",
    "describeJob(job_description)\n",
    "\n",
    "text = soup.get_text() \n",
    "text = md(text)\n",
    "print(text[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"salary_range\": [\n",
      "      {\n",
      "         \"high_end\": \"165000\",\n",
      "         \"low_end\": \"122000\"\n",
      "      }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = create_extraction_chain(llm, salary_range)\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "\n",
    "printOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1572\n",
      "Prompt Tokens: 1561\n",
      "Completion Tokens: 11\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0031439999999999997\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = chain.predict_and_parse(text=text)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
